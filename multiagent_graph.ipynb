{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf0d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/DEV/Documents/langraph/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.tools import tool\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Callable, Union\n",
    "import importlib\n",
    "from langchain.tools import Tool\n",
    "import sys\n",
    "\n",
    "def generic_agent(agent_configs: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Cria dinamicamente agentes com base nas configurações fornecidas.\n",
    "    \n",
    "    Args:\n",
    "        agent_configs: Lista de dicionários contendo configurações dos agentes\n",
    "        \n",
    "    Returns:\n",
    "        Dicionário com os agentes criados, usando o nome do agente como chave\n",
    "    \"\"\"\n",
    "    agents = {}\n",
    "    \n",
    "    for config in agent_configs:\n",
    "        # Extrair informações da configuração\n",
    "        agent_name = config.get(\"name\", config.get(\"agent\", \"unnamed_agent\"))\n",
    "        model_name = config.get(\"model\", \"gpt-3.5-turbo\")\n",
    "        api_key = config.get(\"api_key\", \"\")\n",
    "        prompt = config.get(\"prompt\", \"\")\n",
    "        tool_names = config.get(\"tools\", [])  # Lista de nomes de ferramentas (strings)\n",
    "        \n",
    "        # Converter nomes de ferramentas em objetos Tool do LangChain\n",
    "        tools = []\n",
    "        for tool_name in tool_names:\n",
    "            # Verificar se o nome da ferramenta é uma string\n",
    "            if isinstance(tool_name, str):\n",
    "                # Tentar encontrar a função no escopo global primeiro\n",
    "                if tool_name in globals():\n",
    "                    func = globals()[tool_name]\n",
    "                    # Converter a função em um objeto Tool\n",
    "                    tool = Tool(\n",
    "                        name=tool_name,\n",
    "                        description=f\"Tool para {tool_name}\",\n",
    "                        func=func\n",
    "                    )\n",
    "                    tools.append(tool)\n",
    "                else:\n",
    "                    # Tentar importar do módulo atual\n",
    "                    try:\n",
    "                        # Obter o módulo atual\n",
    "                        current_module = sys.modules[__name__]\n",
    "                        # Verificar se a função existe no módulo atual\n",
    "                        if hasattr(current_module, tool_name):\n",
    "                            func = getattr(current_module, tool_name)\n",
    "                            # Converter a função em um objeto Tool\n",
    "                            tool = Tool(\n",
    "                                name=tool_name,\n",
    "                                description=f\"Tool para {tool_name}\",\n",
    "                                func=func\n",
    "                            )\n",
    "                            tools.append(tool)\n",
    "                        else:\n",
    "                            print(f\"Aviso: Ferramenta {tool_name} não encontrada\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao importar {tool_name}: {e}\")\n",
    "            else:\n",
    "                # Se já é um objeto (não uma string), verificar se tem o atributo 'name'\n",
    "                if hasattr(tool_name, 'name'):\n",
    "                    tools.append(tool_name)\n",
    "                else:\n",
    "                    # Se é uma função, criar um Tool\n",
    "                    tool_func_name = tool_name.__name__ if hasattr(tool_name, '__name__') else \"tool_func\"\n",
    "                    tool = Tool(\n",
    "                        name=tool_func_name,\n",
    "                        description=f\"Tool para {tool_func_name}\",\n",
    "                        func=tool_name\n",
    "                    )\n",
    "                    tools.append(tool)\n",
    "        \n",
    "        # Criar o modelo de linguagem\n",
    "        llm = ChatOpenAI(model=model_name, api_key=api_key)\n",
    "        \n",
    "        # Criar o agente\n",
    "        agent = create_react_agent(\n",
    "            model=llm,\n",
    "            tools=tools,\n",
    "            prompt=prompt,\n",
    "            name=agent_name\n",
    "        )\n",
    "        \n",
    "        # Adicionar ao dicionário de agentes\n",
    "        agents[agent_name] = agent\n",
    "    \n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de709faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "\n",
    "def pretty_print_message(message, indent=False):\n",
    "    pretty_message = message.pretty_repr(html=True)\n",
    "    if not indent:\n",
    "        print(pretty_message)\n",
    "        return\n",
    "\n",
    "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
    "    print(indented)\n",
    "\n",
    "\n",
    "def pretty_print_messages(update, last_message=False):\n",
    "    is_subgraph = False\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "        is_subgraph = True\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        update_label = f\"Update from node {node_name}:\"\n",
    "        if is_subgraph:\n",
    "            update_label = \"\\t\" + update_label\n",
    "\n",
    "        print(update_label)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        messages = convert_to_messages(node_update[\"messages\"])\n",
    "        if last_message:\n",
    "            messages = messages[-1:]\n",
    "\n",
    "        for m in messages:\n",
    "            pretty_print_message(m, indent=is_subgraph)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero.\")\n",
    "    return a / b\n",
    "\n",
    "\n",
    "\n",
    "math_agent = create_react_agent(\n",
    "    model= ChatOpenAI(model=\"gpt-4o\", api_key=\"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\"),\n",
    "    tools=[add, multiply, divide],\n",
    "    prompt=(\n",
    "        \"Voce é um agent de matematica basica.\\n\"\n",
    "        \"Instruções:\\n\"\n",
    "        \"- Ajude SOMENTE em tarefas relacionadas à matemática\\n\"\n",
    "        \"- Depois de concluir suas tarefas, responda diretamente ao supervisor\\n\"\n",
    "        \"- Responda SOMENTE com os resultados do seu trabalho, NÃO inclua NENHUM outro texto.\"\n",
    "    ),\n",
    "    name=\"math_agent\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d605ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1784a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def consulta_cep(cep: str) -> dict:\n",
    "    \"\"\"Busca de CEP\"\"\"\n",
    "    consulta_url = f\"https://viacep.com.br/ws/{cep}/json/\"\n",
    "    response = requests.get(consulta_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return \"erro ao consultar CEP\"\n",
    "\n",
    "\n",
    "a = [{\n",
    "    \"name\":\"cep_agent\",\n",
    "    \"agent\":\"cep_agent\",\n",
    "    \"model\":\"gpt-4o\",\n",
    "    \"api_key\":\"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\",\n",
    "    \"tools\":[\"consulta_cep\"],\n",
    "    \"prompt\":(\"Você é um agent expecializado em procurar codigo postal.\\n\"\n",
    "              \"Instruções:\\n\"\n",
    "              \"- Ajude SOMENTE em tarefas relacionadas à busca de endereço postal\\n\"\n",
    "              \"- Depois de concluir suas tarefas, responda diretamente ao supervisor\\n\"\n",
    "              \"- Responda SOMENTE com os resultados do seu trabalho, NÃO inclua NENHUM outro texto.\")\n",
    "    \n",
    "}]\n",
    "\n",
    "agent = generic_agent(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f1292",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent['cep_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    model=llm,\n",
    "    agents=[agent['cep_agent'], math_agent],\n",
    "    prompt=(\n",
    "        \"Você é um supervisor gerenciando agentes:\\n\"\n",
    "        \"- um agente de codigo postal. Atribua tarefas relacionadas à pesquisa a este agente\\n\"\n",
    "        \"- um agente matemático. Atribua tarefas relacionadas à matemática a este agente\\n\"\n",
    "        \"Atribua trabalho a um agente por vez, não ligue para agentes em paralelo.\\n\"\n",
    "        \"Não faça nenhum trabalho sozinho.\"\n",
    "    ),\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode=\"full_history\",\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = supervisor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"quanto é (2+3)x4 dividir por 2\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    subgraphs=True,\n",
    ")\n",
    "_, data = result\n",
    "final_message = next(\n",
    "    (msg for msg in reversed(data[\"messages\"]) if isinstance(msg, AIMessage) and msg.name == \"supervisor\" and msg.content), \n",
    "    None\n",
    ")\n",
    "\n",
    "if final_message:\n",
    "    print(\"Resposta final do supervisor:\")\n",
    "    print(final_message.content)\n",
    "else:\n",
    "    print(\"Não foi possível encontrar a resposta final.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
